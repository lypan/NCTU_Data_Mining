param = {
   'objective':'multi:softmax',
   'eta':0.3,
   'max_depth':24,
   'num_class':20,
   'colsample_bytree':0.4,
   'min_child_weight':1
}
num_rounds = 100

clf = xgb.train(param, xgb.DMatrix(dtm_train, cuisine_label), num_rounds)


Out[40]:
    test-merror-mean  test-merror-std  train-merror-mean  train-merror-std
0           0.396631         0.006989           0.339653          0.008268
1           0.333895         0.006165           0.262384          0.003625
2           0.305632         0.005948           0.219996          0.005298
3           0.286397         0.004907           0.189735          0.002591
4           0.274101         0.005025           0.166621          0.002171
5           0.265653         0.006237           0.148366          0.001791
6           0.257983         0.006952           0.133524          0.000932
7           0.251898         0.006448           0.120336          0.001380
8           0.246945         0.007082           0.109825          0.001619
9           0.242318         0.008246           0.099642          0.001846
10          0.239125         0.008110           0.090370          0.001771
11          0.235278         0.008574           0.083040          0.002139
12          0.232889         0.007988           0.076163          0.002283
13          0.231154         0.007749           0.069864          0.002205
14          0.228212         0.007911           0.064848          0.002104
15          0.226427         0.007840           0.060045          0.002179
16          0.223711         0.008292           0.055381          0.001745
17          0.223611         0.008350           0.051270          0.001600
18          0.221272         0.008327           0.047536          0.001235
19          0.219386         0.008513           0.044141          0.001232
20          0.218858         0.008455           0.041143          0.001141
21          0.218129         0.008008           0.038232          0.001253
22          0.216545         0.007678           0.035900          0.001040
23          0.215112         0.006649           0.033618          0.001184
24          0.214307         0.006784           0.031644          0.001396
25          0.213100         0.007311           0.029708          0.001392
26          0.212421         0.007164           0.027898          0.001512
27          0.211642         0.006924           0.026446          0.001531
28          0.210862         0.007181           0.025120          0.001483
29          0.210787         0.007922           0.023680          0.001237
..               ...              ...                ...               ...
70          0.199522         0.006328           0.005262          0.000357
71          0.199824         0.006200           0.005085          0.000356
72          0.199698         0.005923           0.004985          0.000348
73          0.199472         0.006655           0.004859          0.000337
74          0.199623         0.006642           0.004714          0.000351
75          0.199598         0.006439           0.004614          0.000378
76          0.199824         0.006228           0.004438          0.000385
77          0.199799         0.006465           0.004268          0.000413
78          0.199548         0.005879           0.004149          0.000425
79          0.199296         0.005886           0.004073          0.000414
80          0.198944         0.005972           0.003960          0.000417
81          0.198969         0.006080           0.003860          0.000365
82          0.198793         0.006204           0.003703          0.000335
83          0.198542         0.006345           0.003602          0.000362
84          0.198516         0.006302           0.003508          0.000347
85          0.198969         0.006356           0.003401          0.000297
86          0.198743         0.005916           0.003281          0.000227
87          0.198592         0.006070           0.003218          0.000211
88          0.198793         0.006041           0.003105          0.000227
89          0.198416         0.005889           0.003043          0.000208
90          0.198517         0.005879           0.002986          0.000215
91          0.198215         0.005748           0.002942          0.000200
92          0.197838         0.006029           0.002835          0.000221
93          0.197863         0.005411           0.002766          0.000218
94          0.197511         0.005522           0.002716          0.000210
95          0.197159         0.005574           0.002703          0.000167
96          0.197360         0.005363           0.002602          0.000194
97          0.197184         0.005268           0.002559          0.000172
98          0.197435         0.005470           0.002514          0.000184
99          0.197536         0.005523           0.002483          0.000227

[100 rows x 4 columns]

xgb.cv(param, xgb.DMatrix(dtm_train, cuisine_label), num_rounds, nfold=5,
       metrics={'merror'}, seed = 0)